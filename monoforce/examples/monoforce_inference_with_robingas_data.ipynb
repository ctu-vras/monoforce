{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## MonoForce Inference with RobInGas Data\n",
    "\n",
    "We are going to load the RobInGas data and perform inference with the pretrained MonoForce model."
   ],
   "id": "53c6a416f8100f1b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# add the path to the source code of the MonoForce package\n",
    "import sys\n",
    "sys.path.append('../src')"
   ],
   "id": "a0481a71fb6484a5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Load the Terrain Encoder model"
   ],
   "id": "ccc06d2b2c36c152"
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from monoforce.models.terrain_encoder.lss import compile_model\n",
    "\n",
    "def load_model(model_path, robot='tradr'):\n",
    "    \"\"\"\n",
    "    Load the MonoForce model from a given path.\n",
    "    :param model_path: str, path to the model\n",
    "    :param robot: str, robot type\n",
    "    :return: MonoForce model\n",
    "    \"\"\"\n",
    "    lss_cfg_path = f'../config/lss_cfg_{robot}.yaml'\n",
    "    lss_cfg = read_yaml(lss_cfg_path)\n",
    "    \n",
    "    model = compile_model(lss_cfg['grid_conf'], lss_cfg['data_aug_conf'], inpC=3, outC=1)\n",
    "    \n",
    "    # https://discuss.pytorch.org/t/how-to-load-part-of-pre-trained-model/1113/3\n",
    "    model_dict = model.state_dict()\n",
    "    pretrained_model = torch.load(model_path)\n",
    "    print(f\"Loading pretrained LSS model from {model_path}\")\n",
    "    model_dict.update(pretrained_model)\n",
    "    model.load_state_dict(model_dict)\n",
    "    model.eval()\n",
    "    \n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "eaf3c22b2faa7c4f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from monoforce.utils import read_yaml\n",
    "\n",
    "robot = 'tradr'\n",
    "model_path = f'../config/weights/lss/lss_robingas_{robot}.pt'\n",
    "model = load_model(model_path, robot=robot)\n",
    "# print(model)"
   ],
   "id": "61de793a36311671",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from monoforce.datasets import RobinGasVis, robingas_seq_paths\n",
    "from monoforce.dphys_config import DPhysConfig"
   ],
   "id": "d1ef108620d3bff6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def compile_data(seq_i=None, robot='tradr', small=False, is_train=False):\n",
    "    \"\"\"\n",
    "    Compile the RobInGas dataset for a given sequence index and robot type.\n",
    "    :param seq_i: int, sequence index\n",
    "    :param robot: str, robot type\n",
    "    :param small: bool, if True, return a small subset of the dataset\n",
    "    :param is_train: bool, if True, return the training set, otherwise the test set\n",
    "    :return: RobinGas dataset\n",
    "    \"\"\"\n",
    "    dphys_cfg = DPhysConfig()\n",
    "\n",
    "    lss_cfg_path = f'../config/lss_cfg_{robot}.yaml'\n",
    "    assert os.path.isfile(lss_cfg_path)\n",
    "    lss_cfg = read_yaml(lss_cfg_path)\n",
    "\n",
    "    if seq_i is not None:\n",
    "        path = robingas_seq_paths[robot][seq_i]\n",
    "    else:\n",
    "        path = np.random.choice(robingas_seq_paths[robot])\n",
    "\n",
    "    ds = RobinGasVis(path=path, dphys_cfg=dphys_cfg, lss_cfg=lss_cfg, is_train=is_train)\n",
    "    if small:\n",
    "        ds = ds[np.random.choice(len(ds), 4, replace=False)]\n",
    "\n",
    "    return ds"
   ],
   "id": "78cd24abe8dce06d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "ds = compile_data(seq_i=0, robot=robot, small=False, is_train=False)\n",
    "print(f\"Number of samples: {len(ds)}\")"
   ],
   "id": "756bb841ea7dfa50",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Visualizing a sample from the dataset."
   ],
   "id": "ba82e9e31ed192f2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "sample = ds[0]\n",
    "(imgs, rots, trans, intrins, post_rots, post_trans,\n",
    " hm_geom, hm_terrain,\n",
    " control_ts, controls,\n",
    " traj_ts, Xs, Xds, Rs, Omegas,\n",
    " points) = sample\n",
    "print(f\"Images shape: {imgs.shape}\")\n",
    "print(f\"Extrinsic Rotations shape: {rots.shape}\")\n",
    "print(f\"Extrinsic Translations shape: {trans.shape}\")\n",
    "print(f\"Intrinsic camera matrix shape: {intrins.shape}\")\n",
    "print(f\"Images augmentation Post-rotation shape: {post_rots.shape}\")\n",
    "print(f\"Images augmentation Post-translation shape: {post_trans.shape}\")\n",
    "print(f\"Heightmap geometric shape: {hm_geom.shape}\")\n",
    "print(f\"Heightmap terrain shape: {hm_terrain.shape}\")\n",
    "print(f\"Control timestamps shape: {control_ts.shape}\")\n",
    "print(f\"Controls shape: {controls.shape}\")\n",
    "print(f\"Trajectory timestamps shape: {traj_ts.shape}\")\n",
    "print(f\"Robot's positions shape: {Xs.shape}\")\n",
    "print(f\"Robot's linear velocities shape: {Xds.shape}\")\n",
    "print(f\"Robot's orientations shape: {Rs.shape}\")\n",
    "print(f\"Robot's angular velocities shape: {Omegas.shape}\")\n",
    "print(f\"Lidar points shape: {points.shape}\")"
   ],
   "id": "fb76b0f5ef3ee27f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from monoforce.models.terrain_encoder.utils import ego_to_cam, get_only_in_img_mask, denormalize_img\n",
    "\n",
    "\n",
    "def explore_data(sample: list, raw_img_size: tuple, model: torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Explore the RobInGas data sample.\n",
    "    :param sample: list, sample from the dataset\n",
    "    :param raw_img_size: tuple, raw image size\n",
    "    :param model: torch.nn.Module, MonoForce model\n",
    "    \"\"\"\n",
    "    H, W = raw_img_size\n",
    "    (imgs, rots, trans, intrins, post_rots, post_trans,\n",
    "     hm_geom, hm_terrain,\n",
    "     control_ts, controls,\n",
    "     traj_ts, Xs, Xds, Rs, Omegas,\n",
    "     points) = sample\n",
    "    height_geom, mask_geom = hm_geom[0], hm_geom[1]\n",
    "    height_terrain, mask_terrain = hm_terrain[0], hm_terrain[1]\n",
    "    n_cams = len(imgs)\n",
    "\n",
    "    frustum_pts = model.get_geometry(rots[None], trans[None], intrins[None], post_rots[None], post_trans[None])\n",
    "    frustum_pts = frustum_pts.squeeze(0)\n",
    "\n",
    "    n_rows, n_cols = 2, int(np.ceil(n_cams / 2) + 3)\n",
    "    plt.figure(figsize=(n_cols * 4, n_rows * 4))\n",
    "    gs = mpl.gridspec.GridSpec(n_rows, n_cols)\n",
    "    gs.update(wspace=0.0, hspace=0.0, left=0.0, right=1.0, top=1.0, bottom=0.0)\n",
    "\n",
    "    final_ax = plt.subplot(gs[:, -1:])\n",
    "    for imgi, img in enumerate(imgs):\n",
    "        cam_pts = ego_to_cam(points, rots[imgi], trans[imgi], intrins[imgi])\n",
    "        mask = get_only_in_img_mask(cam_pts, H, W)\n",
    "        plot_pts = post_rots[imgi].matmul(cam_pts) + post_trans[imgi].unsqueeze(1)\n",
    "\n",
    "        ax = plt.subplot(gs[imgi // int(np.ceil(n_cams / 2)), imgi % int(np.ceil(n_cams / 2))])\n",
    "        plt.imshow(denormalize_img(img))\n",
    "        plt.scatter(plot_pts[0, mask], plot_pts[1, mask], c=points[2, mask],\n",
    "                    s=1, alpha=0.4, cmap='jet', vmin=-1., vmax=1.)\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.sca(final_ax)\n",
    "        plt.plot(frustum_pts[imgi, :, :, :, 0].view(-1), frustum_pts[imgi, :, :, :, 1].view(-1), '.')\n",
    "    \n",
    "    # plot height maps\n",
    "    ax = plt.subplot(gs[:, -3:-2])\n",
    "    plt.imshow(height_geom.T, origin='lower', cmap='jet', vmin=-1., vmax=1.)\n",
    "    plt.title('Heightmap Geometric')\n",
    "    plt.axis('off')\n",
    "\n",
    "    ax = plt.subplot(gs[:, -2:-1])\n",
    "    plt.imshow(height_terrain.T, origin='lower', cmap='jet', vmin=-1., vmax=1.)\n",
    "    plt.title('Heightmap Terrain')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    final_ax.set_aspect('equal')\n",
    "\n",
    "    plt.show()"
   ],
   "id": "4a6358ff5dc87f67",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "raw_img_shape = ds.lss_cfg['data_aug_conf']['H'], ds.lss_cfg['data_aug_conf']['W']\n",
    "print(f\"Raw image shape: {raw_img_shape}\")\n",
    "\n",
    "explore_data(sample, raw_img_size=raw_img_shape, model=model)"
   ],
   "id": "d98d42342f3eefb0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Inference with the MonoForce model"
   ],
   "id": "d5be9d7e6bac6140"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "data_loader = DataLoader(ds, batch_size=1, shuffle=False)\n",
    "batch = next(iter(data_loader))\n",
    "(imgs, rots, trans, intrins, post_rots, post_trans,\n",
    " hm_geom, hm_terrain,\n",
    " control_ts, controls,\n",
    " traj_ts, Xs, Xds, Rs, Omegas,\n",
    " points) = batch\n",
    "\n",
    "start = timer()\n",
    "with torch.inference_mode():\n",
    "    inputs = [imgs, rots, trans, intrins, post_rots, post_trans]\n",
    "    inputs = [i.to(device) for i in inputs]\n",
    "    heightmap_pred = model(*inputs)\n",
    "end = timer()\n",
    "print(f\"Heightmap prediction shape: {heightmap_pred.shape}\")\n",
    "print(f\"Time taken for inference: {end - start} seconds\")\n",
    "print(f\"Device: {list(model.parameters())[0].device}\")"
   ],
   "id": "a00980ab646aaeaf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Visualizing the predicted heightmap"
   ],
   "id": "3593361dd9c8ab53"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "heightmap_pred_np = heightmap_pred.squeeze(1).cpu().numpy()\n",
    "for b in range(heightmap_pred_np.shape[0]):\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.imshow(heightmap_pred_np[b].T, origin='lower', cmap='jet', vmin=-1., vmax=1.)\n",
    "    plt.title('Predicted Heightmap')\n",
    "    plt.axis('off')\n",
    "    plt.colorbar()\n",
    "    plt.show()"
   ],
   "id": "a6615131bd422b03",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Predicting robot's trajectory with $\\nabla$Physics"
   ],
   "id": "5b9e54a133e8fb22"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Defining the control inputs\n",
    "- Left and right velocity commands: $u_1 = u_2 = 1$\n",
    "- Simulation time: $T = 5$ s\n",
    "- Simulation step: $\\Delta t = 0.01$ s"
   ],
   "id": "b4cabe867702c790"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# constant linear and angular velocities as control inputs\n",
    "dphys_cfg = DPhysConfig()\n",
    "\n",
    "T, dt = dphys_cfg.traj_sim_time, dphys_cfg.dt  # dt = T / N = 0.01 s, simulation step\n",
    "N = int(T / dt)\n",
    "controls = torch.tensor([[[1.0, 1.0]] * int(T / dt)]).to(device)  # vel_left, vel_right"
   ],
   "id": "8e9b37d924648d5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from monoforce.models.dphysics import DPhysics\n",
    "\n",
    "dphysics = DPhysics(dphys_cfg=dphys_cfg, device=device)\n",
    "\n",
    "with torch.inference_mode():\n",
    "    states, forces = dphysics(z_grid=heightmap_pred.squeeze(1), controls=controls)"
   ],
   "id": "809bbde34692470c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "Xs, Rs, Xds, Omegas, X_points = states\n",
    "print(f\"Robot's positions shape: {Xs.shape}\")\n",
    "print(f\"Robot's orientation shape: {Rs.shape}\")\n",
    "print(f\"Linear velocity shape: {Xds.shape}\")\n",
    "print(f\"Angular velocity shape: {Omegas.shape}\")\n",
    "print(f\"Robot's body points shape: {X_points.shape}\")"
   ],
   "id": "97677e99b589fc94",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Visualizing the robot's trajectory and heightmap"
   ],
   "id": "6c5879ba64fd1d33"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "xs_grid = Xs.cpu().numpy()\n",
    "xs_grid = xs_grid.reshape(-1, 3)\n",
    "xs_grid = xs_grid[::10]  # downsample for visualization\n",
    "xs_grid = (xs_grid[:, :2] + dphys_cfg.d_max) / dphys_cfg.grid_res  # normalize to grid resolution\n",
    "\n",
    "for b in range(Xs.shape[0]):\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.imshow(heightmap_pred_np.T, origin='lower', cmap='jet', vmin=-1., vmax=1.)\n",
    "    plt.title('Predicted Heightmap')\n",
    "    plt.axis('off')\n",
    "    plt.colorbar()\n",
    "    plt.scatter(xs_grid[0, 0], xs_grid[0, 1], c='red', s=100, label='Start')\n",
    "    plt.scatter(xs_grid[:, 0], xs_grid[:, 1], c='blue', s=1, label='Trajectory')\n",
    "    plt.scatter(xs_grid[-1, 0], xs_grid[-1, 1], c='green', s=100, label='End')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ],
   "id": "6aaf7cdd6ec37d72",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
