{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "sequence = '../data/RobinGas/marv/marv_2024-09-26-13-46-51/'\n",
    "os.listdir(sequence)"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "rgb_path = os.path.join(sequence, 'luxonis', 'rgb')\n",
    "depth_path = os.path.join(sequence, 'luxonis', 'depth')\n",
    "\n",
    "rgb_files = sorted(os.listdir(rgb_path))\n",
    "depth_files = sorted(os.listdir(depth_path))\n",
    "print(len(rgb_files), len(depth_files))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2541b47d731825f2",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "i = np.random.randint(len(rgb_files))\n",
    "rgb = Image.open(os.path.join(rgb_path, rgb_files[i]))\n",
    "depth = Image.open(os.path.join(depth_path, depth_files[i]))\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(rgb)\n",
    "plt.title('RGB')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(depth, cmap='gray')\n",
    "plt.title('Depth')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "26e03e531285abbe",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Depth Camera Intrinsic Parameters\n",
    "\n",
    "To transform the depth image to a point cloud, we need the camera calibration parameters. The calibration files are stored in the `calibration` folder. The camera calibration is stored in the `*.yaml` files and the transformations between the cameras and the lidar are stored in `transformations.yaml`.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7adbc05c32a72893"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "calib_path = os.path.join(sequence, 'luxonis', 'calibration')\n",
    "calib = {}\n",
    "# read cameras-lidar transformations\n",
    "trans_path = os.path.join(calib_path, 'transformations.yaml')\n",
    "with open(trans_path, 'r') as f:\n",
    "    transforms = yaml.load(f, Loader=yaml.FullLoader)\n",
    "f.close()\n",
    "calib['transformations'] = transforms\n",
    "Tr_cam_robot = np.array(transforms['T_oak_rgb_camera_optical_frame__base_link']['data'], dtype=float).reshape(4, 4)\n",
    "print(f'Camera to Robot Transformation:\\n{Tr_cam_robot}')\n",
    "\n",
    "# read camera calibration\n",
    "file = 'luxonis_depth.yaml'\n",
    "with open(os.path.join(calib_path, file), 'r') as f:\n",
    "    cam_info = yaml.load(f, Loader=yaml.FullLoader)\n",
    "    calib[file.replace('.yaml', '')] = cam_info\n",
    "f.close()\n",
    "\n",
    "K = np.array(cam_info['camera_matrix']['data'], dtype=float).reshape(3, 3)\n",
    "print(f'Camera Matrix:\\n{K}')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "718cec232badf9b1",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Depth Image to Point Cloud"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1a1b6fcddee0483f"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Depth image to point cloud\n",
    "def depth_to_pc(depth, K):\n",
    "    H, W = depth.shape\n",
    "    fx, fy = K[0, 0], K[1, 1]\n",
    "    cx, cy = K[0, 2], K[1, 2]\n",
    "\n",
    "    x = np.arange(0, W) - cx\n",
    "    y = np.arange(0, H) - cy\n",
    "    xx, yy = np.meshgrid(x, y)\n",
    "    Z = depth / 1000.0  # mm to meters\n",
    "    X = xx * Z / fx\n",
    "    Y = yy * Z / fy\n",
    "\n",
    "    points = np.stack([X, Y, Z], axis=-1)\n",
    "    points = points.reshape(-1, 3)\n",
    "    return points\n",
    "\n",
    "points = depth_to_pc(np.array(depth), K)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6565fcf5e6936f3c",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import open3d as o3d\n",
    "\n",
    "mask = (points[:, 1] < 0.0)  # remove points below the ground\n",
    "color = np.array(rgb).reshape(-1, 3) / 255.0\n",
    "\n",
    "pcd = o3d.geometry.PointCloud()\n",
    "pcd.points = o3d.utility.Vector3dVector(points[mask])\n",
    "pcd.colors = o3d.utility.Vector3dVector(color[mask])\n",
    "o3d.visualization.draw_geometries([pcd])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "41719dcd8474ea08",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Compare to Lidar Point Cloud"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "643b7a8c61da31e0"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "clouds_path = os.path.join(sequence, 'clouds')\n",
    "cloud_files = sorted(os.listdir(clouds_path))\n",
    "\n",
    "cloud = np.load(os.path.join(clouds_path, cloud_files[i]))['cloud']\n",
    "lidar_points = np.stack([cloud['x'], cloud['y'], cloud['z']], axis=-1)\n",
    "print(lidar_points.shape)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dd5440a16faebba0",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Visualize the lidar point cloud\n",
    "pcd_lidar = o3d.geometry.PointCloud()\n",
    "pcd_lidar.points = o3d.utility.Vector3dVector(lidar_points)\n",
    "o3d.visualization.draw_geometries([pcd_lidar])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c831961b40515a2a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Load the robot-lidar transformation\n",
    "trans_path = os.path.join(sequence, 'calibration', 'transformations.yaml')\n",
    "with open(trans_path, 'r') as f:\n",
    "    transforms = yaml.load(f, Loader=yaml.FullLoader)\n",
    "f.close()\n",
    "# print(transforms.keys())\n",
    "Tr_robot_lidar = np.array(transforms['T_base_link__os_sensor']['data'], dtype=float).reshape(4, 4)\n",
    "print(f'Robot to Lidar Transformation:\\n{Tr_robot_lidar}')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "29ee778acb1482ad",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Transform the lidar point cloud to the robot frame\n",
    "lidar_points_robot = np.dot(Tr_robot_lidar[:3, :3], lidar_points.T).T + Tr_robot_lidar[:3, 3]\n",
    "\n",
    "# Transform depth camera point cloud to robot frame\n",
    "Tr_robot_cam = np.linalg.inv(Tr_cam_robot)\n",
    "points_robot = np.dot(Tr_robot_cam[:3, :3], points.T).T + Tr_robot_cam[:3, 3]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8247a6b7d0597892",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Visualize the point clouds\n",
    "pcd_lidar = o3d.geometry.PointCloud()\n",
    "pcd_lidar.points = o3d.utility.Vector3dVector(lidar_points_robot)\n",
    "pcd_lidar.paint_uniform_color([0, 0, 1])\n",
    "\n",
    "pcd_cam = o3d.geometry.PointCloud()\n",
    "pcd_cam.points = o3d.utility.Vector3dVector(points_robot[mask])\n",
    "pcd_cam.colors = o3d.utility.Vector3dVector(color[mask])\n",
    "\n",
    "o3d.visualization.draw_geometries([pcd_lidar, pcd_cam])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6adbd2da6dc96ef7",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
