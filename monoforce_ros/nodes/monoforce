#!/usr/bin/env python

import os
import numpy as np
import torch
import rospy
from numpy.lib.recfunctions import unstructured_to_structured
from monoforce.datasets import RobinGasPoints, robingas_seq_paths
from monoforce.config import DPhysConfig
from monoforce.models.dphysics import DPhysics, vw_to_track_vel
from monoforce.ros import height_map_to_gridmap_msg, poses_to_path, to_tf, xyz_to_point
from monoforce.models.terrain_encoder.model import compile_model
from nav_msgs.msg import Path
from sensor_msgs.msg import PointCloud2, Image, CameraInfo
from grid_map_msgs.msg import GridMap
from ros_numpy import msgify
from monoforce.utils import read_yaml, position
import rospkg
import tf2_ros
from visualization_msgs.msg import Marker, MarkerArray


class MonoForce:
    def __init__(self,
                 name='monoforce',
                 robot='husky',
                 dphys_config_path=None,
                 lss_config_path=None,
                 lss_weights_path=None,
                 map_frame='map',
                 robot_initial_frame='base_link0',
                 robot_frame='base_link'):
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.robot = robot

        self.dphys_cfg = DPhysConfig()
        self.lib_path = rospkg.RosPack().get_path('monoforce').replace('monoforce_ros', 'monoforce')
        path = np.random.choice(robingas_seq_paths[self.robot])
        if os.path.exists(path):
            self.data_seq = path
        else:
            rospy.loginfo('Data sequence for robot %s does not exist. Using sample data.' % self.robot)
            self.data_seq = os.path.join(self.lib_path, 'config/data_sample', self.robot)
        self.dphys_config_path = dphys_config_path
        assert os.path.isfile(self.dphys_config_path), 'Config file %s does not exist' % self.dphys_config_path
        self.dphys_cfg.from_yaml(self.dphys_config_path)
        self.dphys_cfg.from_rosparams(node_name=name)
        # load dphysics model
        self.dphysics = DPhysics(self.dphys_cfg, device=self.device)

        # load LSS config
        self.lss_config_path = lss_config_path
        assert os.path.isfile(self.lss_config_path), 'LSS config file %s does not exist' % self.lss_config_path
        self.lss_config = read_yaml(self.lss_config_path)

        self.rate = 1 / self.dphys_cfg.dt
        self.map_frame = map_frame
        self.robot_initial_frame = robot_initial_frame
        self.robot_frame = robot_frame
        self.camera_frames = None  # will be set from the data sequence
        # load terrain encoder
        self.terrain_encoder = self.load_terrain_encoder(lss_weights_path)

        # publishers
        self.cloud_pub = rospy.Publisher('cloud', PointCloud2, queue_size=1)
        self.path_pub = rospy.Publisher('path', Path, queue_size=1)
        self.path_gt_pub = rospy.Publisher('path_gt', Path, queue_size=1)
        self.img_pubs = None
        self.caminfo_pubs = None
        self.tf_broadcast = tf2_ros.TransformBroadcaster()
        self.forces_pub = rospy.Publisher('forces', MarkerArray, queue_size=1)

    def load_terrain_encoder(self, lss_weights_path):
        model = compile_model(self.lss_config['grid_conf'], self.lss_config['data_aug_conf'], outC=1)
        rospy.loginfo('Loading model from: %s' % lss_weights_path)
        model.load_state_dict(torch.load(lss_weights_path, map_location=self.device))
        model.eval()
        model.to(self.device)
        return model

    def publish_cloud(self, points, stamp):
        assert points.ndim == 2, 'Points must be of shape (N, 3)'
        assert points.shape[1] == 3, 'Points must be of shape (N, 3)'
        points = np.asarray(points, dtype='float32')
        cloud_struct = unstructured_to_structured(points, names=['x', 'y', 'z'])
        cloud_msg = msgify(PointCloud2, cloud_struct)
        cloud_msg.header.frame_id = self.robot_initial_frame
        cloud_msg.header.stamp = stamp
        self.cloud_pub.publish(cloud_msg)

    def publish_images(self, imgs, Ks, stamp):
        for cam, img, K, img_pub, K_pub in zip(self.camera_frames, imgs, Ks, self.img_pubs, self.caminfo_pubs):
            # images
            img = np.asarray(img, dtype='uint8')
            img_msg = msgify(Image, img, encoding='rgb8')
            img_msg.header.stamp = stamp
            img_msg.header.frame_id = cam.lower()
            img_pub.publish(img_msg)
            # cameras info
            K_msg = CameraInfo()
            P = np.zeros((3, 4))
            P[:3, :3] = K
            R = np.eye(3)
            K_msg.K = K.flatten().tolist()
            K_msg.P = P.flatten().tolist()
            K_msg.R = R.flatten().tolist()
            K_msg.header.stamp = stamp
            K_msg.header.frame_id = cam.lower()
            K_msg.height = img.shape[0]
            K_msg.width = img.shape[1]
            K_pub.publish(K_msg)

    def publish_gridmap(self, height, stamp, topic, mask=None):
        assert isinstance(height, np.ndarray) or isinstance(height, torch.Tensor)
        assert isinstance(mask, np.ndarray) or isinstance(mask, torch.Tensor) or mask is None
        assert isinstance(stamp, rospy.Time)
        assert isinstance(topic, str)

        if isinstance(height, torch.Tensor):
            height = height.squeeze().cpu().numpy()
        if isinstance(mask, torch.Tensor):
            mask = mask.squeeze().cpu().numpy()
        grid_msg = height_map_to_gridmap_msg(height, grid_res=self.dphys_cfg.grid_res, mask=mask)
        grid_msg.info.header.frame_id = self.robot_initial_frame
        grid_msg.info.header.stamp = stamp
        pub = rospy.Publisher(topic, GridMap, queue_size=1)
        pub.publish(grid_msg)

    def publish_forces(self, robot_forces, robot_points, stamp):
        assert robot_forces.shape == robot_points.shape
        assert robot_forces.shape[1] == 3
        # publish forces as arrows with MarkerArray
        markers = MarkerArray()
        for i in range(len(robot_forces)):
            force = robot_forces[i, :]
            xyz = robot_points[i, :]
            marker = Marker()
            marker.header.frame_id = self.robot_frame
            marker.header.stamp = stamp
            marker.id = i
            marker.type = Marker.ARROW
            marker.action = Marker.ADD
            marker.pose.position.x = xyz[0]
            marker.pose.position.y = xyz[1]
            marker.pose.position.z = xyz[2]
            marker.points.append(xyz_to_point([0, 0, 0]))
            marker.points.append(xyz_to_point(force / self.dphys_cfg.robot_mass / 9.8))
            marker.scale.x = 0.05
            marker.scale.y = 0.10
            marker.scale.z = 0.05
            marker.color.a = 1.0
            marker.color.r = 1.0
            marker.color.g = 0.0
            marker.color.b = 0.0
            markers.markers.append(marker)
        self.forces_pub.publish(markers)

    def poses_from_states(self, states):
        xyz = states[0].squeeze().cpu().numpy()
        Rs = states[2].squeeze().cpu().numpy()
        poses = np.stack([np.eye(4) for _ in range(len(xyz))])
        poses[:, :3, :3] = Rs
        poses[:, :3, 3] = xyz
        return poses

    def predict_states(self, z_grid, v, w):
        with torch.no_grad():
            # constant linear and angular velocities as control inputs
            T, dt = self.dphys_cfg.traj_sim_time, self.dphys_cfg.dt
            v_l, v_r = vw_to_track_vel(v, w, self.dphys_cfg.robot_size[1])
            thrusts = self.dphys_cfg.k_thrust * torch.tensor([[v_l, v_r]] * int(T / dt), device=self.device)
            thrusts = thrusts.to(self.device).repeat(z_grid.shape[0], 1, 1)  # [B, N_ts, 2]
            states, forces = self.dphysics(z_grid, controls=thrusts)
        return states, forces

    def run(self):
        ds = RobinGasPoints(self.data_seq, dphys_cfg=self.dphys_cfg, lss_cfg=self.lss_config, is_train=False)
        rospy.loginfo('Loaded dataset with %d samples from path: %s' % (len(ds), self.data_seq))
        sample_i = np.random.choice(range(len(ds)))
        rospy.loginfo('Using sample %d' % sample_i)

        self.camera_frames = ds.cameras
        self.img_pubs = [rospy.Publisher('%s/image' % cam, Image, queue_size=1) for cam in self.camera_frames]
        self.caminfo_pubs = [rospy.Publisher('%s/camera_info' % cam, CameraInfo, queue_size=1) for cam in self.camera_frames]

        imgs, rots, trans, intrins, post_rots, post_trans = ds.get_images_data(sample_i)
        points = position(ds.get_cloud(sample_i))

        traj = ds.get_traj(sample_i)
        poses_gt = traj['poses']

        map_pose = ds.get_pose(sample_i)

        imgs_raw = []
        Ks = []
        for cam in self.camera_frames:
            img_raw, K = ds.get_image(sample_i, cam, undistort=False)
            imgs_raw.append(img_raw)
            Ks.append(K)

        # get heightmap prediction
        with torch.no_grad():
            inputs = [imgs, rots, trans, intrins, post_rots, post_trans]
            inputs = [torch.as_tensor(i[None], device=self.device) for i in inputs]
            voxel_feats = self.terrain_encoder.get_voxels(*inputs)
            height_geom_pred, height_diff_pred = self.terrain_encoder.bevencode(voxel_feats)
            height_terrain_pred = height_geom_pred - height_diff_pred
            # height_terrain_pred = self.model(*inputs)

        rate = rospy.Rate(self.rate)
        pose_i = 0
        poses = None
        robot_points = None
        F_springs = None
        while not rospy.is_shutdown():
            stamp = rospy.Time.now()

            if pose_i == 0:
                # point cloud
                self.publish_cloud(points, stamp)
                # grid map
                self.publish_gridmap(height_geom_pred, stamp, topic='grid_map_geom_pred')
                self.publish_gridmap(height_diff_pred, stamp, topic='grid_map_diff_pred')
                self.publish_gridmap(height_terrain_pred, stamp, topic='grid_map_terrain_pred')
                # images
                self.publish_images(imgs_raw, Ks, stamp)

                # predict path poses
                v = np.random.uniform(0.9, 1.2)
                # if robot has more than one (front-facing) camera, randomly change commanded linear velocity direction
                if len(self.camera_frames) > 1 and np.random.random() > 0.5:
                    v = -v
                w = np.random.uniform(-3.14, 3.14)

                rospy.loginfo('Predicting path with v=%.3f, w=%.3f' % (v, w))
                states, forces = self.predict_states(height_terrain_pred.squeeze(1), v=v, w=w)
                poses = self.poses_from_states(states)
                poses[:, 2, 3] += 0.132  # add robot clearance
                print('Predicted poses shape: %s' % str(poses.shape))
                F_springs = forces[0].squeeze().cpu().numpy()
                print('Predicted forces shape: %s' % str(F_springs.shape))
                robot_points = np.asarray(self.dphys_cfg.robot_points)
                print('Robot contact points shape: %s' % str(robot_points.shape))
                # publish paths
                path_msg = poses_to_path(poses, frame_id=self.robot_initial_frame, stamp=stamp)
                path_gt_msg = poses_to_path(poses_gt, frame_id=self.robot_initial_frame, stamp=stamp)
                self.path_pub.publish(path_msg)
                self.path_gt_pub.publish(path_gt_msg)

            # robot pose in map frame
            tf = to_tf(map_pose, self.map_frame, self.robot_initial_frame, stamp)
            self.tf_broadcast.sendTransform(tf)
            # camera poses
            for cam, tran, rot in zip(self.camera_frames, trans, rots):
                pose = np.eye(4)
                pose[:3, :3] = rot.numpy()
                pose[:3, 3] = tran.numpy()
                tf = to_tf(pose, self.robot_initial_frame, cam, stamp)
                self.tf_broadcast.sendTransform(tf)

            # robot's current pose
            robot_traj_pose = poses[pose_i]
            assert robot_traj_pose.shape == (4, 4)
            tf = to_tf(robot_traj_pose, self.robot_initial_frame, self.robot_frame, stamp)
            self.tf_broadcast.sendTransform(tf)

            # publish forces
            self.publish_forces(F_springs[pose_i], robot_points, stamp)

            pose_i = (pose_i + 1) % len(poses)
            rate.sleep()


def main():
    rospy.init_node('monoforce', anonymous=True, log_level=rospy.DEBUG)
    
    lib_path = rospkg.RosPack().get_path('monoforce').replace('monoforce_ros', 'monoforce')
    rospy.loginfo('Library path: %s' % lib_path)
    robot = rospy.get_param('~robot', 'husky')
    dphys_config_path = rospy.get_param('~dphys_config_path', os.path.join(lib_path, 'config/dphys_cfg.yaml'))
    lss_config_path = rospy.get_param('~lss_config_path', os.path.join(lib_path, f'config/lss_cfg_{robot}.yaml'))
    lss_weights_path = rospy.get_param('~lss_weights_path', os.path.join(lib_path, f'config/weights/lss/lss_robingas_{robot}.pt'))
    map_frame = rospy.get_param('~map_frame', 'map')
    robot_initial_frame = rospy.get_param('~robot_initial_frame', 'base_link0')
    robot_frame = rospy.get_param('~robot_frame', 'base_link')
    
    node = MonoForce(robot=robot,
                     dphys_config_path=dphys_config_path,
                     lss_config_path=lss_config_path,
                     lss_weights_path=lss_weights_path,
                     map_frame=map_frame,
                     robot_initial_frame=robot_initial_frame,
                     robot_frame=robot_frame)
    try:
        node.run()
    except rospy.ROSInterruptException:
        rospy.loginfo('Shutting down monoforce node')


if __name__ == '__main__':
    main()
